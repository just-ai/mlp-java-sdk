### LlamaConfig
Представляет конфигурацию для Llama модели.

- `temperature`: Температура для генерации текста (по умолчанию 0.6).
- `top_p`: Параметр top_p для генерации текста (по умолчанию 0.9).
- `max_gen_len`: Максимальная длина генерируемого текста (необязательно).

### LlamaTextRequest
Представляет запрос для генерации текста с помощью Llama.

- `text`: Исходный текст для генерации.

### LlamaTextResponse
Представляет ответ сгенерированным текстом от Llama.

- `value`: Сгенерированный текст.

### LlamaChatRole
Роль автора сообщения в чате Llama.

- `system`: Системное сообщение.
- `user`: Сообщение пользователя.
- `assistant`: Сообщение ассистента.

### LlamaMessage
Представляет сообщение в чате Llama.

- `role`: Роль автора сообщения (system, user, assistant).
- `content`: Содержимое сообщения.

### LlamaChatRequest
Представляет запрос для проведения чата с помощью Llama.

- `dialog`: Список сообщений в диалоге.

### LlamaChatResponse
Представляет ответ на чат-запрос с помощью Llama.

- `message`: Сообщение, сгенерированное моделью Llama.

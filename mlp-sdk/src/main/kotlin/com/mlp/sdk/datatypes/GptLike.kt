//package com.mlp.sdk.datatypes
//
//import com.fasterxml.jackson.annotation.JsonProperty
//
///**
// * This data class represents all possible config options for chat-gpt request.
// * This object could be posted as predict config and could be used in predict method to simplify requests.
// * Meaning of each field is identical to ChatCompletionRequest.
// * Values in ChatCompletionRequest have higher priority.
// */
//data class ChatCompletionConfig(
//    val model: String? = null,
//    val temperature: Double? = null,
//    @JsonProperty("top_p")
//    val topP: Double? = null,
//    val n: Int? = null,
//    val stop: List<String>? = null,
//    @JsonProperty("max_tokens")
//    val maxTokens: Int? = null,
//    @JsonProperty("presence_penalty")
//    val presencePenalty: Double? = null,
//    @JsonProperty("frequency_penalty")
//    val frequencyPenalty: Double? = null,
//    @JsonProperty("logit_bias")
//    val logitBias: Map<String, Int>? = null,
//    val user: String? = null,
//
//    /**
//     * System prompt could be specified in config. It will be placed on the first place in messages array.
//     * If messages already has message with role=system then this value will be skipped
//     */
//    @JsonProperty("system_prompt")
//    val systemPrompt: String? = null
//)
//
///**
// * Constants for 'role' field
// */
//enum class ChatCompletionRole {
//    system,
//    user,
//    assistant,
//}
//
///**
// * Simplified form of ChatGPT request without any additional options
// */
//data class ChatCompletionSimpleRequest(
//    val messages: List<ChatMessage>,
//)
//
//
//data class Usage(
//    /**
//     * Number of tokens in the prompt.
//     */
//    @JsonProperty("prompt_tokens") val promptTokens: Long,
//    /**
//     * Number of tokens in the generated completion.
//     */
//    @JsonProperty("completion_tokens") val completionTokens: Long,
//    /**
//     * Total number of tokens used in the request (prompt + completion).
//     */
//    @JsonProperty("total_tokens") val totalTokens: Long
//)
//
//data class ChatMessage(
//    /**
//     * The role of the author of this message.
//     */
//    val role: ChatCompletionRole,
//    /**
//     * The contents of the message.
//     */
//    val content: String
//)
//
//enum class ChatCompletionChoiceFinishReason {
//    stop,
//    length
//}
//
//data class ChatCompletionChoice(
//    /**
//     * The index of the choice in the list of choices.
//     */
//    val index: Int,
//    /**
//     * A chat completion message generated by the model.
//     */
//    val message: ChatMessage,
//    /**
//     * The reason the model stopped generating tokens.
//     * This will be stop if the model hit a natural stop point or a provided stop sequence, length if the maximum number of tokens specified in the request was reached, or function_call if the model called a function.
//     */
//    @JsonProperty("finish_reason") val finishReason: ChatCompletionChoiceFinishReason? = null
//)
//
//data class ChatCompletionChunk(
//    /**
//     * A unique identifier for the chat completion chunk.
//     */
//    val id: String? = null,
//
//    /**
//     * The object type, which is always chat.completion.chunk.
//     */
//    val `object`: String? = null,
//
//    /**
//     * The Unix timestamp (in seconds) of when the chat completion chunk was created.
//     */
//    val created: Long = 0,
//
//    /**
//     * The model used for the chat completion.
//     */
//    val model: String,
//
//    /**
//     * A list of chat completion choices. Can be more than one if n is greater than 1.
//     */
//    val choices: List<ChatCompletionChoice>,
//)
//
//data class ChatCompletionChunkChoice(
//    /**
//     * The index of the choice in the list of choices.
//     */
//    val index: Int,
//    /**
//     * A chat completion delta generated by streamed model responses.
//     */
//    val delta: ChatMessage,
//    /**
//     * The reason the model stopped generating tokens.
//     * This will be stop if the model hit a natural stop point or a provided stop sequence, length if the maximum number of tokens specified in the request was reached, or function_call if the model called a function.
//     */
//    @JsonProperty("finish_reason") val finishReason: String
//)
//
